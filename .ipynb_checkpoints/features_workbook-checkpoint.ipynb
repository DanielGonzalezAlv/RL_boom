{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.4\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import agent_code.my_agent.algorithms as alg\n",
    "from settings import s\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('C:/Users/Lily/Documents/UNI/FML/project/local_branch/data-collection/75-crate-no-opponents.pickle', 'rb')\n",
    "data = pickle.load(file)\n",
    "data = sorted(data, key=lambda k: k['state']['step'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to easily change to different game states\n",
    "i = 2\n",
    "#extract information from game_state\n",
    "game_state = data[i]['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[14  1]\n",
      " [15  1]\n",
      " [13  1]\n",
      " [12  1]\n",
      " [11  1]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-172-e1c1e02042ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#feat_dist_to_safe(game_state)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'next-action'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgame_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'self'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'state'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'self'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-171-5c168d080813>\u001b[0m in \u001b[0;36mfeature4\u001b[1;34m(game_state)\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[0msafe_loc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatch\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[0mfree_space\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatch\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlook_for_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfree_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0magent_loc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe_loc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[1;31m#print(safe_loc)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-121-61775965411c>\u001b[0m in \u001b[0;36mlook_for_targets\u001b[1;34m(free_space, start, targets, logger)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mfrontier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mparent_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mdist_so_far\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mbest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "#feat_dist_to_safe(game_state)\n",
    "print(feature4(game_state), data[i]['next-action'])\n",
    "print(game_state['self'], data[i-1]['state']['self'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blast_coords(bomb, arena, arr):\n",
    "    x, y = bomb[0], bomb[1]\n",
    "    if len(arr)== 0:\n",
    "       arr = np.array([[x,y]])\n",
    "       #np.append(a, [[0,1]], axis=0)\n",
    "    \n",
    "    for i in range(1, 3+1):\n",
    "        if arena[x+i,y] == -1: break\n",
    "        arr = np.append(arr,[[x+i,y]], axis=0)\n",
    "    for i in range(1, 3+1):\n",
    "        if arena[x-i,y] == -1: break\n",
    "        arr = np.append(arr,[[x-i,y]], axis=0)            \n",
    "    for i in range(1, 3+1):\n",
    "        if arena[x,y+i] == -1: break\n",
    "        arr = np.append(arr,[[x,y+i]], axis=0)            \n",
    "    for i in range(1, 3+1):\n",
    "        if arena[x,y-i] == -1: break\n",
    "        arr = np.append(arr,[[x,y-i]], axis=0)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature4(game_state):\n",
    "    '''\n",
    "    This feature rewards the action that minimizes the distance to safety\n",
    "    should the agent be in the danger zone(where explosions will be).\n",
    "        F(s,a) = 1, should a reduces distance to safety\n",
    "        F(s,a) = 0, otherwise\n",
    "    F(s,a) returns 0 if we are not in the danger zone   \n",
    "    \n",
    "    We begin by extracting all relevant information from game_state\n",
    "    '''\n",
    "    agent = game_state['self']\n",
    "    arena = game_state['arena']\n",
    "    bombs = game_state['bombs']\n",
    "    '''\n",
    "    and initializing the resulting vector\n",
    "    '''\n",
    "    res = np.zeros(6, dtype=np.int8)\n",
    "    if len(bombs) != 0:\n",
    "        '''\n",
    "        If there are bombs on the game board, we map all the explosions\n",
    "        that will be caused by the bombs. For this, we use the help function\n",
    "        get_blast_coords. This is an adjusted version of the function with the\n",
    "        same name from item.py of the original framework\n",
    "        '''\n",
    "        danger_zone = []\n",
    "        for b in bombs:\n",
    "            danger_zone= get_blast_coords(b, arena, danger_zone)\n",
    "        print(danger_zone)\n",
    "        '''\n",
    "        We then check if the agent is in the danger zone\n",
    "        If agent is not in the danger zone, we return 0.\n",
    "        Otherwise we calculate the distance/direction of safety.\n",
    "        '''\n",
    "        if agent[0] in danger_zone[:,0] and agent[1] in danger_zone[:,1]:\n",
    "            \n",
    "            '''\n",
    "            we then mark these explosions on our map. here we deep-copy\n",
    "            the arena, so that in the case that the arena is needed for\n",
    "            other features, it remains unchanged\n",
    "            '''\n",
    "            map = copy.deepcopy(arena)\n",
    "            map[danger_zone[:,0], danger_zone[:,1]] = 2\n",
    "\n",
    "            '''\n",
    "            to take consideration of only the necessary area and not the whole map,\n",
    "            we create a patch of the map surrounding where the explosions will be.\n",
    "            To do this, we calculate the min_x, min_y, max_x, and max_y of the explosion\n",
    "            locations and create a box surrounding all the explosions using these points\n",
    "            '''\n",
    "            min_x = np.amin(danger_zone[:,0])-1%17\n",
    "            min_y = np.amin(danger_zone[:,1])-1%17\n",
    "            max_x = np.amax(danger_zone[:,0])+2%17\n",
    "            max_y = np.amax(danger_zone[:,1])+2%17\n",
    "\n",
    "            patch = map[ min_x:max_x, min_y:max_y ]\n",
    "            #print(patch)\n",
    "\n",
    "            '''\n",
    "            now that we have the patch with all the explosions marked, we can find the \n",
    "            safe locations on the map. These would be the tiles marked as 0 \n",
    "            '''\n",
    "            safe_loc = np.argwhere(patch==0)\n",
    "            free_space = abs(patch) != 1\n",
    "            d = look_for_targets(free_space, agent_loc, safe_loc)\n",
    "            print(d)\n",
    "            #print(safe_loc)\n",
    "            \n",
    "            '''\n",
    "            we then calculate the minimum distance of our agent to any of these safe locations.\n",
    "            For simplicity, only Manhattan distance is used to calculate distance in this\n",
    "            feature extraction. However, this doesn't always represent the true distance in the \n",
    "            game because of the walls.(Possible point of improvement?)\n",
    "            '''\n",
    "            dist_to_safe = np.min(abs(agent_loc[0]- safe_loc[:,0]) + abs(agent_loc[1] - safe_loc[:,1]))\n",
    "\n",
    "            '''\n",
    "            Then, we calculate the positions of our agent after taking all possible actions.\n",
    "            '''\n",
    "            actions_loc = np.array([[agent[0], agent[1]-1], #up\n",
    "                                    [agent[0], agent[1]+1], #down\n",
    "                                    [agent[0]-1, agent[1]], #left\n",
    "                                    [agent[0]+1, agent[1]], #right\n",
    "                                    [agent[0], agent[1]],   #bomb\n",
    "                                    [agent[0], agent[1]]])  #wait\n",
    "            '''\n",
    "            For each of these new positions, we then calculate the minimum distance from the new \n",
    "            position to the safe locations.\n",
    "            '''\n",
    "            new_dist_to_safe = [np.min(abs(action[0]- safe_loc[:,0]) + \n",
    "                                      abs(action[1] - safe_loc[:,1])) for action in actions_loc]\n",
    "\n",
    "            '''\n",
    "            TO WRITE\n",
    "            '''\n",
    "            print(new_dist_to_safe, dist_to_safe)\n",
    "            res[np.where(new_dist_to_safe-dist_to_safe<0)] = 1\n",
    "        \n",
    "    return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def look_for_targets(free_space, start, targets, logger=None):\n",
    "    \"\"\"Find direction of closest target that can be reached via free tiles.\n",
    "    Performs a breadth-first search of the reachable free tiles until a target is encountered.\n",
    "    If no target can be reached, the path that takes the agent closest to any target is chosen.\n",
    "    Args:\n",
    "        free_space: Boolean numpy array. True for free tiles and False for obstacles.\n",
    "        start: the coordinate from which to begin the search.\n",
    "        targets: list or array holding the coordinates of all target tiles.\n",
    "        logger: optional logger object for debugging.\n",
    "    Returns:\n",
    "        coordinate of first step towards closest target or towards tile closest to any target.\n",
    "    USEFUL FOR feature1\n",
    "    \"\"\"\n",
    "    if len(targets) == 0: return None\n",
    "\n",
    "    frontier = [start]\n",
    "    parent_dict = {start: start}\n",
    "    dist_so_far = {start: 0}\n",
    "    best = start\n",
    "    best_dist = np.sum(np.abs(np.subtract(targets, start)), axis=1).min()\n",
    "\n",
    "    while len(frontier) > 0:\n",
    "        current = frontier.pop(0)\n",
    "        # Find distance from current position to all targets, track closest\n",
    "        d = np.sum(np.abs(np.subtract(targets, current)), axis=1).min()\n",
    "        if d + dist_so_far[current] <= best_dist:\n",
    "            best = current\n",
    "            best_dist = d + dist_so_far[current]\n",
    "        if d == 0:\n",
    "            # Found path to a target's exact position, mission accomplished!\n",
    "            best = current\n",
    "            break\n",
    "        # Add unexplored free neighboring tiles to the queue in a random order\n",
    "        x, y = current\n",
    "        neighbors = [(x,y) for (x,y) in [(x+1,y), (x-1,y), (x,y+1), (x,y-1)] if free_space[x,y]]\n",
    "        shuffle(neighbors)\n",
    "        for neighbor in neighbors:\n",
    "            if neighbor not in parent_dict:\n",
    "                frontier.append(neighbor)\n",
    "                parent_dict[neighbor] = current\n",
    "                dist_so_far[neighbor] = dist_so_far[current] + 1\n",
    "    if logger: logger.debug(f'Suitable target found at {best}')\n",
    "    # Determine the first step towards the best found target tile\n",
    "    current = best\n",
    "    while True:\n",
    "        if parent_dict[current] == start: return current\n",
    "        current = parent_dict[current]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "free_space = arena == 0\n",
    "d = look_for_targets(free_space, (1,1), [[1,2], [10,1]])\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
